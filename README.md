# Neurodata-_Lab_API_Exercice
Exercise using Neurodata Lab API capabilities

This exercise allows us to use the different keys of the Neurodata Lab API. The streaming processing and the webcam did not work with my network, so I modified the exercise using two mp4 videos on my computer. 

In this exercice, I created a Face Detector key and an Emotion Recognition key to use them on two different videos. 


The exercise is divided into three codes: 

1/ main_FaceDetector.py allows you to create a rectangle around the face of the video.

2/ main_EmotionRecognition.py displays the emotion of each individual present on the video with the associated percentage.

3/ main_Emojifaces.py allows you to replace each emotion felt by each individual present on the video with an emoji.
