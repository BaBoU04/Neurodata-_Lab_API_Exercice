# Neurodata-_Lab_API_Exercice
Exercise using Neurodata Lab API capabilities

This exercise allows us to use the different keys of the Neurodata Lab API. We will learn how to use Neurodata Lab API tool, how to process images and videos, and how to create your own real-time stream processing tool using Neurodata Lab API. In consequence, we have example.py and streaming_processing.py that can be executed with a command line.

The streaming processing and the webcam did not work with my network after use cam.py, so I modified the exercise using two mp4 videos on my computer. 

In this exercice, I created a Face Detector key and an Emotion Recognition key to use them on two different videos. 


The exercise is divided into three codes: 

1/ main_FaceDetector.py allows you to create a rectangle around the face of the video.

2/ main_EmotionRecognition.py displays the emotion of each individual present on the video with the associated percentage.

3/ main_Emojifaces.py allows you to replace each emotion felt by each individual present on the video with an emoji.
